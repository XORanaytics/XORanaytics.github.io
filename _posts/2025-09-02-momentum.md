## Momentum

---

### Preface

Some mathematical notations to know:

- $\mathbb{R}$ means a real-valued scalar like $5$, $2.5$, $\pi$, etc. Other scalars are $\mathbb{N}$ for the natural mumbers, $\mathbb{Z}$ for integers, and $\mathbb{Q}$ for rational numbers. We will be commonly using $\mathbb{R}$, $\mathbb{N}$, and $mathbb{Z}$ to represent scalars.
- $\mathbb{R}^D$ means a $D$-dimensional column vector where the entries are real-valued so if $x \in \mathbb{R}^D$, then $x = (x_1, ..., x_D)$ where each $x_i \in \mathbb{R}$.
- $M_{r \times c}(\mathbb{R})$ means a matrix with $r$ rows and $c$ columns where the entries are real-valued.

---

### Momentum

The most basic optimization method to to optimize neural networks is
<a href="/2025/09/02/gradient-descent.html"> gradient descent </a>.
However, gradient descent can be quite slow to converge.
One technique to make gradient descent faster is momentum.
Imagine a ball rolling down a hill.
If the hill was steep, the ball should be moving faster as it rolls down.
If the hill was flat, the ball should be slowing down.
In other words, if the previous gradients are increasing,
then the current gradient should be faster than usual.
The equations to implement momentum is:

$$m_{t+1} = \beta m_t - \eta_t [\frac{\partial f}{\partial x}]_{x = x_t}$$

$$x_{t+1} = x_t + m_{t+1}$$

where $\beta \in [0,1)$ control the amount of momentum and $m_0 = 0 \in \mathbb{R}^D$.
Note if $\beta = 0$ so there is no momentum, then momentum equations simplify to just gradient descent!
To show that is really happening, let's expand the momentum equation.
Let $g_t = [\frac{\partial f}{\partial x}]_{x = x_t}$.

$$m_{t+1}
= \beta m_t - \eta_t g_t
= \beta(\beta m_{t-1} - \eta_{t-1} g_{t-1}) - \eta_t g_t
= ...
= -\sum_{j=0}^{t-1} \beta^j \eta_{t-j} g_{t-j}$$

Thus, momentum is just an exponentially weighted average of all the gradients up to iteration $t$.
Thus, if $g_t$ is increasing over time $t$, then $m_{t+1} > g_t$ (i.e. momentum is faster than gradient descent).
But if the current gradient $g_t$ switches direction, then momentum $m_{t+1}$ slows down
so during fall regions of $f$ (i.e. where the minimum is), the movement moves past the minimum slightly
and then, falls back into the minimum.

---

### Nesterov Momentum

A variant of momentum is Nesterov momentum.
Nesterov momemtum aims to be perform movements based on looking one-step ahead
so that perhaps movements do not oscillate as much neat the minimum.
The equations to implement Nesterov momentum is:

$$m_{t+1} = \beta m_t - \eta_t [\frac{\partial f}{\partial x}]_{x = x_t + \beta m_t}$$

$$x_{t+1} = x_t + m_{t+1}$$

where $\beta \in [0,1)$ and $m_0 = 0 \in \mathbb{R}^D$.
Note the only different between Nesterov momentum and momentum is the gradient is evaluated at
$x = x_t + \beta m_t$ instead of $x = x_t$.
So, Nesterov momentum aims to lower oscillation by reducing the amount of movement that the gradient
overshoots the minimum near flat regions since the gradient at $x = x_t + \beta m_t$ is smaller
than $x = x_t$ as the region becomes more flat.
Note however Nesterov momentum may be slower to converge than momentum since the same reasoning also
means movement can be slower at the start.

---

### Momentum with Neural Networks

Suppose our neural network is defined:

$$f(x; \theta) = f_L(x; \theta_L)$$

where

- Pre-activation: $z_{\ell} = W_{\ell} f_{\ell-1}(x; \theta_{\ell-1}) + b_{\ell}$
- Neuron: $f_{\ell}(x; \theta_{\ell}) = \phi_{\ell}(z_{\ell}; V_{\ell})$

And suppose we want to minimize MSE loss $L(\theta) = \frac{1}{n} \sum_{i=1}^n (y_i - f_L(x_i))^2$
where our data is $(x_1, y_1), ..., (x_n, y_n)$ and the parameters we want to learn
are $\theta_{\ell} = \{ W_{\ell}, b_{\ell} \}$ for $\ell = 1, ..., L$.

Recall that gradient descent for feed-forward neural networks for EACH parameters $W_{\ell}$ and $b_{\ell}$ are:

$$(W_{\ell})_{t+1} = (W_{\ell})_t - \eta_t [\frac{\partial L}{\partial W_{\ell}}]_{W_{\ell} = (W_{\ell})_t}$$

$$(b_{\ell})_{t+1} = (b_{\ell})_t - \eta_t [\frac{\partial L}{\partial b_{\ell}}]_{b_{\ell} = (b_{\ell})_t}$$

To change gradient descent to instead momentum is simple:

$$m_{W_{\ell}, t+1} = \beta m_{W_{\ell}, t} - \eta_t [\frac{\partial L}{\partial W_{\ell}}]_{W_{\ell} = (W_{\ell})_t}$$

$$m_{b_{\ell}, t+1} = \beta m_{b_{\ell}, t} - \eta_t [\frac{\partial L}{\partial b_{\ell}}]_{b_{\ell} = (b_{\ell})_t}$$

$$(W_{\ell})_{t+1} = (W_{\ell})_t + m_{W_{\ell}, t+1}$$

$$(b_{\ell})_{t+1} = (b_{\ell})_t + m_{b_{\ell}, t+1}$$
